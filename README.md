# Estimador de precios de propiedades
Proyecto final del Bootcamp de Data Science y MLOps, dictado por Escuela de Datos Vivos

## üìä **Parte 1 ‚Äî EDA y Preparaci√≥n de Datos**

*   **Conclusiones de negocio y Storytelling**: ver en la secci√≥n *Conclusiones de negocio* m√°s abajo
*   **C√≥digo y comentarios:** ver el archivo notebooks/01-eda.ipynb

## ü§ñ **Parte 2 ‚Äî Modelado y Evaluaci√≥n**

*   **Notebook de modelado:** 
- Ver los scripts dentro de la carpeta *scripts/models*. Para una mayor explicaci√≥n del proceso de modelado, consultar la secci√≥n *Explicaci√≥n del proceso de modelado de datos* de este archivo.
*   **Insights del modelo:**:
- Las variables seleccionadas para entrenar el modelo influyeron en la precisi√≥n del mismo, pero no tanto como el l√≠mite que se establezca para el precio de los registros a utilizar en el modelo.
- Randomized Search ofrece un modelo con bajo error en train, pero no garantiza que el error sea similar en test. Por lo tanto, busqu√© modelos m√°s estables mediante GridSearchCV, que tengan un error un poco m√°s alto en train, pero m√°s cercano al error de test.  
*   **Justificaci√≥n de variables:**
-   Descart√© las variables "available_publication", "days_since_start", "days_since_end" porque no est√°n correlacionadas con el precio. Adem√°s, un usuario siempre consultar√° por propiedades que est√©n disponibles.
- Tambi√©n descart√© "surface_uncovered", ya que se obtiene a partir de la resta entre superficie total y la cubierta, siendo estas m√°s comunes a la hora de consultar por una propiedad.
*   **Exportaci√≥n del modelo:**
- El modelo fue exportado mediante MLFlow. Puede encontrarse en la carpeta *mlruns/512582443179615027/models/m-0248ec91bbc349f393da1c30e4f3fed1/artifacts/model.pkl* 

## üñ•Ô∏è **Parte 3 ‚Äî Interfaz con Gradio y Deploy en Hugging Face Spaces**

El principal desaf√≠o al construir la interface fue la gesti√≥n de las variables de latitud y longitud, ya que no fue posible implementar un mapa para que el usuario indicara estos puntos, por lo que estas variables quedaron codificadas con un valor promedio.

Opt√© por guardar previamente los valores m√≠nimos y m√°ximos admitidos para cada columna, limitando al usuario a ingresar inputs adecuados. Sin embargo, se nota que si se ingresan valores poco razonables en cuanto a la proporci√≥n de habitaciones o superficies, la proyecci√≥n de precio suele estancarse ignorando la zona o el tipo de propiedad. Esto subraya la necesidad de limitar la proporci√≥n entre los valores de entrada del usuario.

*   **Url del Hugging Face Space:** 
https://huggingface.co/spaces/alejo-cuello/proyecto-final-bootcamp-ds-mlops

*   **Aplicaci√≥n en funcionamiento:**

![Pantalla principal de la app](assets/app-gradio-propia.png)

*   **Uso del endpoint proporcionado:**

![Api de gradio](assets/app-gradio-api.png)

## ‚úÖ Aprendizajes t√©cnicos relevantes:
- Para agilizar el entrenamiento de modelos ante datasets tan grandes, el muestreo es una buena opci√≥n, siempre que sea una proporci√≥n representativa del total.
- El proyecto ense√±√≥ la relevancia de la automatizaci√≥n: se aprendi√≥ a realizar el tracking de las pruebas con MLflow, lo cual fue muy √∫til. Esto permiti√≥ parametrizar f√°cilmente las distintas corridas ejecutadas, teniendo a simple vista todos los resultados de hiperpar√°metros y scores.

## Anexo:

### üîπ Conclusiones de negocio
**¬øAlguna vez viste una propiedad donde la superficie cubierta es mayor que la total?**

Parece absurdo, pero en los datos ocurre, y muchas de esas publicaciones ni siquiera est√°n disponibles. De hecho, la mayor√≠a del mercado ya est√° fuera de l√≠nea, como si las mejores oportunidades hubieran desaparecido antes de tiempo.

**¬øPor qu√© es tan dif√≠cil encontrar casas en Capital Federal?**

Porque su proporci√≥n es m√≠nima en comparaci√≥n con otros tipos de propiedades. Y aun as√≠, las m√°s caras siguen concentr√°ndose all√≠ y en GBA Norte, donde tambi√©n se encuentran los inmuebles de mayor tama√±o y superficie.

**¬øLas zonas baratas comparten alg√∫n patr√≥n?**

S√≠: GBA Oeste y GBA Sur muestran una distribuci√≥n de precios pr√°cticamente id√©ntica, mucho m√°s accesible. Adem√°s, aunque las publicaciones finalizadas son similares entre zonas, las que siguen activas presentan diferencias m√°s marcadas.

**¬øInfluyen la antig√ºedad o la ubicaci√≥n exacta en el precio?**

Sorprendentemente, casi nada: latitud, longitud y d√≠as de publicaci√≥n tienen muy poca correlaci√≥n con el valor en d√≥lares.

**¬øQu√© caracter√≠sticas influyen en el precio de una propiedad m√°s all√° de la zona y el tipo de propiedad?**

Lo que realmente importa es m√°s tangible: cu√°ntos ba√±os tiene la propiedad y cu√°nta superficie cubierta ofrece.

### üîπExplicaci√≥n del proceso de modelado de datos:
Mi fase de modelado comenz√≥ con el Random Forest Regressor, elegido por ser una alternativa s√≥lida para un primer acercamiento. Inici√© con una divisi√≥n del 30% para la data de prueba, aunque r√°pidamente me ajust√© al 20% para obtener mejores resultados en la evaluaci√≥n del rendimiento. El objetivo era optimizar los hiperpar√°metros mientras evaluaba m√©tricas cruciales como R cuadrado, MAE (Error Absoluto Medio) y MSRE (Error Cuadr√°tico Medio).

Apliqu√© primero la b√∫squeda aleatoria (Randomized Search) para encontrar los mejores ajustes iniciales. Aunque luego ajust√© estos par√°metros con Grid Search CV, el error del mejor modelo segu√≠a siendo notablemente grande y muy variable entre los datos de entrenamiento y prueba. Esta inestabilidad me oblig√≥ a dar un paso crucial hacia atr√°s en la limpieza de datos para mejorar la predicci√≥n, confirmando que la limpieza nunca termina.

![Rancomized search](assets/rfr-model-randomizedsearch.png)

La decisi√≥n m√°s importante fue eliminar los outliers de registros con precios muy elevados, ya que generaban sesgos significativos en las predicciones. Esta intervenci√≥n provoc√≥ una mejora notable en la estabilidad y el rendimiento del modelo de Random Forest, reduciendo el error. Al volver a aplicar Randomized Search y luego Grid Search, pude enfocarme en un modelo m√°s estable, priorizando menor diferencia de error entre train y test. Este l√≠mite de precio m√°ximo tambi√©n lo trabaj√© como un par√°metro de las corridas, ya que es un dato importante de considerar a la hora de decidirse por un modelo.

![Rancomized search](assets/rfr-model-gridsearch.png)

Paralelamente a la optimizaci√≥n del random forest, tambi√©n explor√© el modelo m√°s sencillo y r√°pido de Regresi√≥n Lineal. Aunque realic√© los mismos ajustes, como variar las columnas consideradas y aplicar el recorte de outliers, sus resultados de rendimiento fueron consistentemente mucho m√°s bajos. En comparaci√≥n con los modelos de Random Forest, la Regresi√≥n Lineal no demostr√≥ ser una alternativa viable para esta tarea predictiva.

![lr-model.png](assets/lr-model.png)

La clave para gestionar esta serie de experimentos y ajustes ‚Äîque me hicieron ir y venir‚Äî fue la implementaci√≥n de MLflow. MLflow lo utilic√© para el tracking de todos los hiperpar√°metros, scores y variables, permitiendo una r√°pida evaluaci√≥n de las distintas corridas ejecutadas. Pude parametrizar todo f√°cilmente en archivos .py, asegurando que cada resultado obtenido quedara registrado de forma sencilla y automatizada.

**M√©tricas del modelo seleccionado:**
- mae_train: 22617.86
- mae_test: 30077.74
- p2_train: 0.83
- p2_test: 0.71
- rmse_train: 32523.89
- rmse_test: 43379.21

### üîπPuntos de mejora:
- Se podr√≠a probar la agrupaci√≥n de variables categ√≥ricas que se mantuvieron en consideraci√≥n pero que cuentan con pocos registros.
- Tambi√©n ser√≠a √∫til normalizar las distintas variables; por ejemplo, la superficie suele ser un n√∫mero much√≠simo mayor que la cantidad de ambientes, y normalizarlas podr√≠a mejorar el rendimiento.
- Para entender la influencia real de cada factor, una mejora clave ser√≠a utilizar Shap para evaluar el peso de las variables en el modelo.
- Adem√°s, sumar√≠a informaci√≥n el an√°lisis visual de la distribuci√≥n del error de los residuos del modelo, junto con el an√°lisis de la curva ROC respecto a los datos de train y test.
- Otro punto crucial es refinar el preprocesamiento; se sugiere variar el orden en que se ejecutaron las imputaciones, la detecci√≥n de outliers y el llenado de nulos para observar c√≥mo var√≠a el resultado.
- Adem√°s, para capturar din√°micas m√°s complejas, se podr√≠a analizar la relaci√≥n no lineal entre las variables, quiz√°s mediante el uso de MIC.
- Tambi√©n ser√≠a √∫til analizar gr√°ficamente las correlaciones y medir la correlaci√≥n de las variables categ√≥ricas utilizando encoding.

### üîπDefinici√≥n con la gente del negocio:
Entiendo que ser√≠a importante negociar el rendimiento del modelo con los stakeholders o la gente de negocio. No se trata solo de minimizar el error t√©cnico, sino de evaluar qu√© error es aceptable y qu√© alcance tendr√° la predicci√≥n. Es crucial saber negociar qu√© se puede predecir con el modelo en funci√≥n del error m√°ximo admitido.

La exclusi√≥n de los outliers de precios muy elevados demostr√≥ ser una decisi√≥n que redefini√≥ el alcance del modelo, ya que generaban mucho sesgo en la predicci√≥n.
Al ser pocas las casas muy grandes y caras, lo m√°s sensato fue dejarlas por fuera para limitar la predicci√≥n a casas y departamentos m√°s comunes. Esto requiere definir con el negocio si ese error y ese l√≠mite en el alcance son aceptables.

Se subray√≥ la importancia de poseer un criterio s√≥lido y conocimiento del negocio inmobiliario durante todo el proceso. Este conocimiento es una gran ayuda a la hora de analizar los datos, permitiendo identificar qu√© variables tienen m√°s potencial de influir en el precio. Esto orienta significativamente tanto el an√°lisis exploratorio como la limpieza de los datos.

Otro punto vital es que, aunque se realice una primera limpieza de datos con buen criterio, los resultados del modelo pueden no ser los esperados, obligando a volver hacia atr√°s en el proceso.
